# HW1使用Python3.6，pyspark2.3.0
## 创建Python虚拟环境 （Python3.6)
    python3.6 -m venv env
## 安装pyspark
    pip install pyspark==2.3.0

## Reference/Tutorial when doing homework
* [Apache Spark with Python - Pyspark - YouTube](https://www.youtube.com/playlist?list=PL0hSJrxggIQr6wA8buIn1Yxu810ugGed-)

# Scala Version:
Follow the slides to build the environment
* create an SBT project (2.11.0)
* add spark environment
* write code
* build jar

## Reference for scala
* [BUILDING A SCALA PROJECT WITH INTELLIJ AND SBT](https://docs.scala-lang.org/getting-started/intellij-track/building-a-scala-project-with-intellij-and-sbt.html)